{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/raeubaen/giagu/blob/master/NB_LogisticRegression_LC1_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Regressione Logistica e Ricerca di Particelle Supersimmetriche #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Informazioni\n",
        "\n",
        "scopo: imparare a risolvere un problema di classificazioen tramite un classificatore lineare di regressione logistica, prendere dimestichezza con la libreria scikit-learn e imparare l'uso del package Pandas per la gestione di dataset complessi\n",
        "\n",
        "campione di esempi: [SUSY dataset](https://archive.ics.uci.edu/ml/datasets/SUSY) da [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php).\n",
        "\n",
        "Ci focalizzermeo in una task di classificazione binaria (segnale (SUSY) - fondo (processi del Modello Standard con stessi stati finali di quelli prodotti nei decadimenti delle particelle supersimmetriche)).\n",
        "\n",
        "\n",
        "**Regressione logistica**\n",
        "\n",
        "\u00c8 una dei modelli classici del ML per la classificazione che permette di introdurre la maggior parte delle idee e techniche del ML supervisionato. \n",
        "\n",
        "Ogni set di fatures $\\mathbf{x}_i$ \u00e8 associato ad una label di categoria (classe)$C_i\\in\\{1,0\\}$, con $i=1\\ldots n$.\n",
        "Di seguito il feature vector $\\mathbf{x}_i$ \u00e8 ridefinito via the augmented rapresentation $\\mathbf{x}\\rightarrow (1,\\mathbf{x})$. \n",
        "La likelihood function della regressione logistica \u00e8 data dalla funzione sigmoide:\n",
        "\n",
        "$$\n",
        "P(c_i=1)=1-P(c_i=0)= {1 \\over 1+ e^{-\\mathbf{w}\\cdot \\mathbf{x}_i}},\n",
        "$$\n",
        "\n",
        "in cui $\\mathbf{w}$ sono i pesi che definiscono il modello di regressione logistica e che vengono scelti massimizzando la log-likelihood sul campione di dati di training. \n",
        "\n",
        "Definendo la funzione:\n",
        "$$\n",
        "f(a)={1 \\over 1+ e^{-a}},\n",
        "$$\n",
        "\n",
        "con derivata rispetto a $a$:\n",
        "$$\n",
        "{df \\over da}= f(1-f).\n",
        "$$\n",
        "\n",
        "e definendo $f_i \\equiv f(\\mathbf{w}\\cdot \\mathbf{x}_i)$, possiamo esprimere la likelihood dei dati $\\{ \\mathbf{x}_i, C_i \\}$ come:\n",
        "\n",
        "$$\n",
        "P(Data|\\mathbf{x})= \\prod_{i=1}^n f_i^{C_i}(1-f_i)^{1-C_i}\n",
        "$$\n",
        "\n",
        "con log-likelihood:\n",
        "$$\n",
        "\\log{P(Data|\\mathbf{w})}= \\sum_{i=1}^n C_i \\log f_i + (1-C_i)\\log(1-f_i)\n",
        "$$\n",
        "\n",
        "La log-likelihood cambiata di segno fornisce la loss function ed \u00e8 chiamata cross-entropy error function:\n",
        "$$\n",
        "\\mathrm{Cross\\,Entropy}=E(\\mathbf{w})= -\\sum_{i=1}^n C_i \\log f_i + (1-C_i)\\log(1-f_i).\n",
        "$$\n",
        "\n",
        "Osserviamo che:\n",
        "$$\n",
        "\\nabla E(\\mathbf{w})=\\sum_{i=1}^n (f_i-C_i)\\mathbf{x}_i.\n",
        "$$\n",
        "\n",
        "cio\u00e8 il gradiente punta nella direzione della somma delle direzioni dei vettori del training set pesata con la differenza tra la label vera e la probabilit\u00e0 di predire la label stessa.\n",
        "\n",
        "La stima di massima verosimiglianza (MLE) corrisponde alla minimizzazione della cross-entropia. Questo pu\u00f2 essere fatto usando metodi di discesa lungo il gradiente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Passo 1: carica il dataset con pandas\n",
        "\n",
        "**informazioni sul dataset:**\n",
        "\n",
        ">Provide all relevant informatioThe data has been produced using Monte Carlo simulations. The first 8 features are kinematic properties measured by the particle detectors in the accelerator. The last ten features are functions of the first 8 features; these are high-level features derived by physicists to help discriminate between the two classes.\n",
        "\n",
        "* data format: The first column is the class label (1 for signal, 0 for background), followed by the 18 features (8 low-level features then 10 high-level features):: lepton 1 pT, lepton 1 eta, lepton 1 phi, lepton 2 pT, lepton 2 eta, lepton 2 phi, missing energy magnitude, missing energy phi, MET_rel, axial MET, M_R, M_TR_2, R, MT2, S_R, M_Delta_R, dPhi_r_b, cos(theta_r1). For detailed information about each feature see the original paper.\n",
        "\n",
        "\n",
        "* reference: <cite> P. Baldi, P. Sadowski, and D. Whiteson. \"Searching for Exotic Particles in High-energy Physics with Deep Learning.\" Nature Communications 5 (July 2, 2014)</cite>.\n",
        "\n",
        "Il campione che potete scaricare da qui [Campione SUSY.csv 1M eventi](https://www.dropbox.com/s/qfvjlrdz38goien/SUSY.csv?dl=0) contiene solo 1M degli 11M di eventi del dataset totale (per mantenere la size limitata).\n",
        "\n",
        "Importiamo il dataset cono pandas usando i primi 950k eventi come training set e i secondi 50k come test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importing the SUSY Data set\n",
        "import sys, os\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "#warnings.filterwarnings('ignore') #se non si vogliono ricevere warning scommentare questa riga\n",
        "\n",
        "\n",
        "seed=12345\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Download SUSY.csv \n",
        "filename=\"/content/drive/My Drive/Colab Notebooks/dataset/SUSY.csv\"\n",
        "#filename=sample_data/SUSY.csv' \n",
        "\n",
        "columns=[\"signal\", \"lepton 1 pT\", \"lepton 1 eta\", \"lepton 1 phi\", \"lepton 2 pT\", \"lepton 2 eta\", \n",
        "         \"lepton 2 phi\", \"missing energy magnitude\", \"missing energy phi\", \"MET_rel\", \n",
        "         \"axial MET\", \"M_R\", \"M_TR_2\", \"R\", \"MT2\", \"S_R\", \"M_Delta_R\", \"dPhi_r_b\", \"cos(theta_r1)\"]\n",
        "\n",
        "# Load 950k rows as train data, 50k as test data\n",
        "df_train=pd.read_csv(filename,names=columns,nrows=950000,engine='python')\n",
        "df_test=pd.read_csv(filename,names=columns,nrows=50000, skiprows=950000,engine='python')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Definizione funzioni utili in pandas:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "#accede in pandas ai dati del campione di training e li formatta in modo comodo\n",
        "def getTrainData(nVar):\n",
        "    designMatrix = df_train.iloc[:,1:nVar+1].values\n",
        "    #now the signal\n",
        "    labels = df_train['signal'].values # labels (0 or 1)\n",
        "    return (designMatrix,labels)\n",
        "\n",
        "#accede in pandas ai dati del campione di test e li formatta in modo comodo \n",
        "def getTestData(nVar):\n",
        "    designMatrix = df_test.iloc[:,1:nVar+1].values\n",
        "    #now the signal\n",
        "    labels = df_test['signal'].values\n",
        "    return (designMatrix,labels)\n",
        "\n",
        "# usa pandas per costruire curve pseudo-ROC\n",
        "def build_roc_curve(probs, signal_bit, threshes):\n",
        "    # Convert things to a pandas series to build a DataFrame\n",
        "    # which will make ROC curve logic easier to express\n",
        "    signal_probs = pd.Series(probs[:,1])\n",
        "    signal_true = pd.Series(signal_bit)\n",
        "    signal_df = pd.DataFrame(signal_probs, columns=['sig_prob'])\n",
        "    signal_df.loc[:,'sig_true'] = signal_true\n",
        "    Acceptance = []\n",
        "    Rejection = []\n",
        "    for thresh in threshes:\n",
        "        # define acceptance\n",
        "        signal_df.loc[:,'accept'] = signal_df['sig_prob'] > thresh\n",
        "        # sum over data frame with slicing conditions\n",
        "        nSigCor = len(signal_df[(signal_df['accept']) & (signal_df['sig_true']==1.)])\n",
        "        nSig = len(signal_df[signal_df['sig_true']==1.])\n",
        "        nBkgCor = len(signal_df[ (signal_df['sig_true']==0.) & (~signal_df['accept'])])\n",
        "        nBkg = len(signal_df[signal_df['sig_true']==0.])\n",
        "        Acceptance.append(nSigCor/nSig) # False positive rate\n",
        "        Rejection.append(nBkgCor/nBkg) # True positive rate\n",
        "\n",
        "    return Acceptance, Rejection"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Passo 2:  Training  del modello lineare tipo logistic regression con scikit-learn\n",
        "\n",
        "**definizione dei modelli:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "#logistic discriminant con regolarizzazione L2\n",
        "def runSciKitRegressionL2(nVar, alpha):\n",
        "    X_train, y_train = getTrainData(nVar)\n",
        "    X_test, y_test = getTestData(nVar)\n",
        "    clf = SGDClassifier(loss=\"log\", penalty=\"l2\",alpha=alpha,max_iter=5,tol=None)\n",
        "    clf.fit(X_train,y_train.ravel())\n",
        "    predictions = clf.predict(X_test)\n",
        "    print('Accuracy on test data with alpha %.2E : %.3f' %(alpha,clf.score(X_test,y_test)) )\n",
        "    probs = clf.predict_proba(X_test)\n",
        "\n",
        "    #get signal acceptance and background rejection\n",
        "    thresholds = np.arange(0,1,.01)\n",
        "    Acceptance, Rejection = build_roc_curve(probs, y_test, thresholds)\n",
        "    return (probs, Acceptance, Rejection)\n",
        "\n",
        "#logistic discriminant con regolarizzazione L1\n",
        "def runSciKitRegressionL1(nVar,alpha):\n",
        "    X_train, y_train = getTrainData(nVar)\n",
        "    X_test, y_test = getTestData(nVar)\n",
        "    clf = SGDClassifier(loss=\"log\", penalty=\"l1\",alpha=alpha,max_iter=5,tol=None)\n",
        "    clf.fit(X_train,y_train.ravel())\n",
        "    predictions = clf.predict(X_test)\n",
        "    print('Accuracy on test data with alpha %.2E : %.3f' %(alpha,clf.score(X_test,y_test)) )\n",
        "    probs = clf.predict_proba(X_test)\n",
        "\n",
        "    #get signal acceptance and background rejection\n",
        "    thresholds = np.arange(0,1,.01)\n",
        "    Acceptance, Rejection = build_roc_curve(probs, y_test, thresholds)\n",
        "    return (probs,Acceptance,Rejection)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training e valutazione del modello con regolarizzazione L1**\n",
        "\n",
        "* usiamo inizialmente solo le prime 8 feature (low-level)\n",
        "* $\\alpha$ parametro che definisce il peso del termine di regolarizzazione e che va scelto in modo da missimizzare le prestazioni"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.close()\n",
        "alphas = np.logspace(-10,1,11)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "it=0\n",
        "for alpha in alphas:\n",
        "    c1 = 1.*( float(it) % 3.)/3.0\n",
        "    c2 = 1.*( float(it) % 9.)/9.0\n",
        "    c3 = 1.*( float(it) % 27.)/27.0\n",
        "    probs,accept,rej = runSciKitRegressionL1(8,alpha)\n",
        "    ax.scatter(accept,rej,c=[[c1,c2,c3]],label='Alpha: %.1E' %alpha)\n",
        "    it+=1\n",
        "\n",
        "ax.set_xlabel('signal efficiency')\n",
        "ax.set_ylabel('background rejection')\n",
        "plt.legend(loc='lower left', fontsize = 'small');\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Osservazioni:**\n",
        "\n",
        "abbiamo ottenuto un accuracy del 77% che \u00e8 gi\u00e0 piuttosto buona per un'analisi di questo tipo. Tramite la curva pseudo-ROC il fisico delle particelle pu\u00f2 decidere il punto ottimale di lavoro per la data analisi (i.e. la condizione efficienza segnale vs reieizione fondo che ottimizza per esempio la sensibilit\u00e0 di scoperta).\n",
        "\n",
        "Notiamo anche che i risultati sono sensibili al peso della regolarizzazione $\\alpha$. In particolare i risultati delle punti della curva a peggiori prestazioni (verde scuro) indicano che in questi casi il modello non \u00e8 in grado di distinguere tra le due classi. \n",
        "\n",
        "Ci aspettiamo che questo succeda per valori di $\\alpha$ pi\u00f9 grandi, perch\u00e8 la regolarizzazione L1 effttivamente tende a \"spegnere\" la maggior parte delle osservabili (costringe i pesi ad essere vicini a zero), di conseguenza la classificazione risulta in effetti nel tracciare una superficie nella distribuzione di pochissime (probabilmente una sola) fetaure in input, classificando gli eventi di segnale quelli da una pate della superficie e di fondo quelli dall'altra.\n",
        "\n",
        "Per verificarlo plottiamo la probabilit\u00e0 di segnale e fondo ricostruite dal modello per il caso di $\\alpha$ ottimale ($\\alpha = 3.98E-04$) e per il caso peggiore ($\\alpha = 0.79$):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# grafico delle probabilit\u00e0 delle due classi:\n",
        "probsSimple,accep,rej = runSciKitRegressionL1(8,3.98e-4)\n",
        "Signal = df_test.iloc[:,0:1]\n",
        "\n",
        "df_test_acc = pd.DataFrame({'PROB':probsSimple[:,1]})\n",
        "df_test_acc['SIG']=Signal\n",
        "df_test_acc_sig = df_test_acc.query('SIG==1')\n",
        "df_test_acc_bkg = df_test_acc.query('SIG==0')\n",
        "df_test_acc_sig.plot(kind='hist',y='PROB',color='blue',alpha=0.5,bins=np.linspace(0,1,10),label='Signal')\n",
        "df_test_acc_bkg.plot(kind='hist',y='PROB',color='red',label='Background')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# grafico delle probabilit\u00e0 delle due classi:\n",
        "probsSimple,accep,rej = runSciKitRegressionL1(8,0.79)\n",
        "Signal = df_test.iloc[:,0:1]\n",
        "\n",
        "df_test_acc = pd.DataFrame({'PROB':probsSimple[:,1]})\n",
        "df_test_acc['SIG']=Signal\n",
        "df_test_acc_sig = df_test_acc.query('SIG==1')\n",
        "df_test_acc_bkg = df_test_acc.query('SIG==0')\n",
        "df_test_acc_sig.plot(kind='hist',y='PROB',color='blue',alpha=0.5,bins=np.linspace(0,1,10),label='Signal')\n",
        "df_test_acc_bkg.plot(kind='hist',y='PROB',color='red',label='Background')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ottimizziamo ora usando tutte e 18 le osservabili ... ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.close()\n",
        "alphas = np.logspace(-10,1,11)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "it=0\n",
        "for alpha in alphas:\n",
        "    c1 = 1.*( float(it) % 3.)/3.0\n",
        "    c2 = 1.*( float(it) % 9.)/9.0\n",
        "    c3 = 1.*( float(it) % 27.)/27.0\n",
        "    probs,accept,rej = runSciKitRegressionL1(18,alpha)\n",
        "    ax.scatter(accept,rej,c=[[c1,c2,c3]],label='Alpha: %.1E' %alpha)\n",
        "    it+=1\n",
        "\n",
        "ax.set_xlabel('signal efficiency')\n",
        "ax.set_ylabel('background rejection')\n",
        "plt.legend(loc='lower left', fontsize = 'small');\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# grafico delle probabilit\u00e0 delle due classi:\n",
        "probsSimple,accep,rej = runSciKitRegressionL1(18,3.98e-4)\n",
        "Signal = df_test.iloc[:,0:1]\n",
        "\n",
        "df_test_acc = pd.DataFrame({'PROB':probsSimple[:,1]})\n",
        "df_test_acc['SIG']=Signal\n",
        "df_test_acc_sig = df_test_acc.query('SIG==1')\n",
        "df_test_acc_bkg = df_test_acc.query('SIG==0')\n",
        "df_test_acc_sig.plot(kind='hist',y='PROB',color='blue',alpha=0.5,bins=np.linspace(0,1,10),label='Signal')\n",
        "df_test_acc_bkg.plot(kind='hist',y='PROB',color='red',label='Background')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "abbiamo migliorato l'accuracy che ora \u00e8 del 79% e, come atteso dall'usare pi\u00f9 features, \u00e8 diminuita la dipedenza dalla regolarizzazione..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b> Esercizi:</b>\n",
        "\n",
        "* provare ad usare la regolarizzazione L2, i risultati migliorano?\n",
        "\n",
        "* provare a addestrare il modello dopo aver normalizzato i dati in input in modo che abbiano simile dinamica, i risultati cambiano? \n",
        "\n",
        "* provare ad usare dei tagli rettangolari sulle osservabili migliori, calcolate le prestaizoni in termini di efficienza e reiezione e confrontate con la ROC curva ottenuta con la regressione logistica ... \n",
        "\n",
        "* provate a pensare se sia possibile selezionare una regione del campione dei dati di training che permetta di migliorare le prestazioni (suggerimento: pensare a dove il guadagano dall'uso del ML ha pi\u00f9 valore rispetto ad una analisi tradizionale cut-based)."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
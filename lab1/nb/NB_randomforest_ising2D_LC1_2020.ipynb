{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/raeubaen/giagu/blob/master/NB_randomforest_ising2D_LC1_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classificazione stato di un modello di Ising 2D con Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Informazioni ###\n",
        "\n",
        "scopo: imparare ad usare ensamble di modelli deboli tipo foreste random di alberi a decisione binaria \n",
        "applicazione: classificazione dello fase in cui si trovano configurazioni d i un modello di Ising 2D\n",
        "ML tool: cikit-learn\n",
        "\n",
        "\n",
        "### Modello di Ising 2D ###\n",
        "\n",
        "dettagli (definizione teorica e simulazione) nella [nota](https://vixra.org/pdf/1710.0021v2.pdf).\n",
        "\n",
        "\u00c8 definito su un reticolo bidimensionale dall'Hamiltoniana \n",
        "\n",
        "$$ H = -J\\sum_{\\langle ij\\rangle}S_{i}S_j,\\qquad \\qquad S_j\\in\\{\\pm 1\\} $$\n",
        "\n",
        "in cui gli indici del reticolo $i,j$ sono associati ai primi vicini di un reticolo 2D quadrato di lato $L$, e $J$ \u00e8 un parametro di scala arbitrario che definisce la scala dell'energia di interazione tra gli spin $S_i$.\n",
        "Si utilizzano condizioni periodiche al contorno sul reticolo.\n",
        "\n",
        "Si dimostra che questo sistema presenta una transizione di fase nel limite termodinamico da un sistea ordinato con tutti gli spin allineati (ferromagnete ordinato) a una fase disordinata con spin random, alla temperatura critica $T_c/J=1/\\log(1+\\sqrt{2})\\approx 2.26$. \n",
        "\n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "100k configurazioni con $T/J$ uniforme in $[0,5]$ di un modello ising 2D su un reticolo $28\\times 28$ simulato tramite un semplice Monte Carlo tipo Metropolis. \n",
        "\n",
        "Il campione \u00e8 disponibile qui:\n",
        "\n",
        "* [configurazioni](https://www.dropbox.com/s/ma1n1r2uejb9iei/ising_conf.dat?dl=0)\n",
        "* [label](https://www.dropbox.com/s/dj1urxh8tsadoh5/ising_label.dat?dl=0)\n",
        "\n",
        "NOTA: le configurazioni sono 28x28 valori dello spin, le label sono la temperatura associata ad ogni configurazione.\n",
        "\n",
        "Poich\u00e9 \u00e8 noto che vicino alla temepratura critica $T_c$, la lunghezza delle correlazioni ferromagnetiche diverge, rendendo difficile identificare la fase, dvideremo il campione in tre sotto-campioni:\n",
        "\n",
        "* ordinato: $T/J<2.0$\n",
        "* critico: $2.0\\leq T/J\\leq 2.5$\n",
        "* disordinato: $T/J>2.5$\n",
        "\n",
        "e addestreremo il modello usando solo le configurazioni ordinate e disordinate. Poi testeremo il tutto su tutte le configurazioni."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 1: load e pre-processamento del dataset ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed() # shuffle random seed generator\n",
        "\n",
        "# Ising model parameters\n",
        "L=28 # size del reticolo\n",
        "J=1.0 # Ising interaction (1 ferromagnetico, -1 anti-ferromagnetico)\n",
        "T_c=2.26 # Temperatura critica"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#leggiamo le configurazioni ising dal file usando numpy (100k esempi oguno da 28x28 spin)\n",
        "data = np.loadtxt('/content/drive/My Drive/Colab Notebooks/dataset/ising_conf.dat')\n",
        "print(data.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTA: gli esempi sono scritti nel file come righe sequenziali da 28 valori l'una -> 100k x 28 = 2800000 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# al fine di visualizzare alcune delle configurazioni convertiamo il vettore numpy un tensore di 100K eventi ognuno \n",
        "# formato da una matrice 28x28 di spin\n",
        "data = data.reshape(100000,28,28)\n",
        "print(data.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#esempio\n",
        "print(data[2]) #stampa 3zo evento una matrice 28x28 di valori dello spin (-1,1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#leggiamo da file le label associate:\n",
        "labels = np.loadtxt('/content/drive/My Drive/Colab Notebooks/dataset/ising_label.dat')\n",
        "print(labels.shape)\n",
        "print(labels[3]) #temperatura della configurazione del 4to evento"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# dividiamo il campione in 3 campioni sulla base dello stato (ordinato, critico, disordinato)\n",
        "# T/J < 2.0 ordinato\n",
        "# T/J > 2.5 disordinato\n",
        "# altrimenti critico\n",
        "\n",
        "ord_sele = (labels < 2.0)\n",
        "dis_sele = (labels > 2.5)\n",
        "cri_sele = ((labels >= 2.0) & (labels <= 2.5))\n",
        "    \n",
        "print(cri_sele)\n",
        "\n",
        "data_ord = data[ord_sele]\n",
        "data_dis = data[dis_sele]\n",
        "data_cri = data[cri_sele]\n",
        "\n",
        "print(data_ord.shape) \n",
        "print(data_cri.shape) \n",
        "print(data_dis.shape)   \n",
        "\n",
        "labels_ord = np.zeros(data_ord.shape[0])\n",
        "labels_dis = np.ones(data_dis.shape[0])\n",
        "\n",
        "labels_critic = labels[cri_sele]\n",
        "print(labels_critic)\n",
        "labels_cri = labels_critic.copy()\n",
        "labels_cri[labels_critic>T_c] = 1\n",
        "labels_cri[labels_critic<=T_c] = 0\n",
        "\n",
        "print(labels_ord)\n",
        "print(labels_dis)\n",
        "print(labels_cri)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#una rappresentazione grafica pi\u00f9 bella\n",
        "%matplotlib inline \n",
        "\n",
        "#import ml_style as style\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "# set colourbar map\n",
        "cmap_args=dict(cmap='plasma_r')\n",
        "\n",
        "# plot states\n",
        "fig, axarr = plt.subplots(nrows=1, ncols=3)\n",
        "\n",
        "axarr[0].imshow(data_ord[4],**cmap_args)\n",
        "axarr[0].set_title('ordered phase',fontsize=16)\n",
        "axarr[0].tick_params(labelsize=16)\n",
        "\n",
        "axarr[1].imshow(data_cri[4],**cmap_args)\n",
        "axarr[1].set_title('critical region',fontsize=16)\n",
        "axarr[1].tick_params(labelsize=16)\n",
        "\n",
        "im=axarr[2].imshow(data_dis[4],**cmap_args)\n",
        "axarr[2].set_title('disordered phase',fontsize=16)\n",
        "axarr[2].tick_params(labelsize=16)\n",
        "\n",
        "fig.subplots_adjust(right=2.0)\n",
        "\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##Dividiamo il campione per il training\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_to_test_ratio=0.8 # training samples\n",
        "\n",
        "# define training and test data sets\n",
        "X=np.concatenate((data_ord,data_dis))\n",
        "Y=np.concatenate((labels_ord,labels_dis))\n",
        "\n",
        "# selezioniamo random data points dai campioni ordinati e disordinati per cerare training e test\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=train_to_test_ratio,test_size=1.0-train_to_test_ratio)\n",
        "\n",
        "X_critical = data_cri\n",
        "Y_critical = labels_cri\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('Y_train shape:', Y_train.shape)\n",
        "print()\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_critical.shape[0], 'critical samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# riformattiamo i tensori in modo che abbiano l'input corretto atteso dagli alberi a decisione binaria \n",
        "# (vettori flat di features)   (N,28,28) -> (N, 28*28 = 784)\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 28*28))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 28*28))\n",
        "X_critical = np.reshape(X_critical, (X_critical.shape[0], 28*28))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 2: addestramento della Random Forests\n",
        "\n",
        "**Iperparametri**\n",
        "\n",
        "Usiamo l'implementazione in [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) che ha due iperparamteri principali che possono modificare anche sensibimente le prestazioni del modello e il livelo di overfit/underfit: il numero di alberi nella foresta e la complessit\u00e0 di ciascun albero: il primo \u00e8 controllato dal parametro `n_estimators`, mentre la complesiit\u00e0 \u00e8 controllata da vari parametri `min_samples_split`, `min_samples_leaf`, `min_impurity_decrease`, etc, in parte correlati tra loro. Nell'esempio in esame per semplicit\u00e0 useremo solo `min_samples_split` (governa il numero di campioni necessari per procedere ad uno split di un nodo: pi\u00f9 alto \u00e8 il numero minore sar\u00e0 la segmentazione e le diramazioni dell'albero.\n",
        "\n",
        "**NOTA: Stime OOB (Out of Bag)**\n",
        "\n",
        "\u00c8 un metodo molto utile per ottimizzare gli iperparametri quanod si usano metodi di bagging: consiste nel verificare quanto bene funziona il classificatore su qyegli eventi del trainign set che non sono stati usati nel training (perch\u00e8 non campionati nella technica di boostrap). Gioca un ruolo simile alla k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Scikit-learn Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "import warnings\n",
        "#disabilitiamo messaggi di warning \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Valore del numero di alberi \n",
        "min_estimators = 10\n",
        "max_estimators = 101\n",
        "classifer = RandomForestClassifier\n",
        "\n",
        "n_estimator_range=np.arange(min_estimators, max_estimators, 10) #testiamo 10 valori per il primo iperparametro\n",
        "\n",
        "leaf_size_list=[2,10000] #testiamo due valori per il seocondo iperparametro (alta segmentazione e bassa segmentazione)\n",
        "\n",
        "m=len(n_estimator_range)\n",
        "n=len(leaf_size_list)\n",
        "\n",
        "#Allocate Arrays for various quantities\n",
        "RFC_OOB_accuracy=np.zeros((n,m))\n",
        "RFC_train_accuracy=np.zeros((n,m))\n",
        "RFC_test_accuracy=np.zeros((n,m))\n",
        "RFC_critical_accuracy=np.zeros((n,m))\n",
        "run_time=np.zeros((n,m))\n",
        "\n",
        "print_flag=True\n",
        "\n",
        "for i, leaf_size in enumerate(leaf_size_list):\n",
        "    # Define Random Forest Classifier\n",
        "    myRF_clf = classifer(\n",
        "        n_estimators=min_estimators,\n",
        "        max_depth=None, \n",
        "        min_samples_split=leaf_size, # minimum number of sample per leaf\n",
        "        oob_score=True,\n",
        "        random_state=0,\n",
        "        warm_start=True # When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest.\n",
        "    )\n",
        "    for j, n_estimator in enumerate(n_estimator_range):\n",
        "        \n",
        "        print('n_estimators: %i, leaf_size: %i'%(n_estimator,leaf_size))\n",
        "        \n",
        "        start_time = time.time()\n",
        "        myRF_clf.set_params(n_estimators=n_estimator)\n",
        "        myRF_clf.fit(X_train, Y_train)\n",
        "        run_time[i,j] = time.time() - start_time\n",
        "\n",
        "    # check accuracy\n",
        "        RFC_train_accuracy[i,j]=myRF_clf.score(X_train,Y_train)\n",
        "        RFC_OOB_accuracy[i,j]=myRF_clf.oob_score_\n",
        "        RFC_test_accuracy[i,j]=myRF_clf.score(X_test,Y_test)\n",
        "        RFC_critical_accuracy[i,j]=myRF_clf.score(X_critical,Y_critical)\n",
        "        if print_flag:\n",
        "            result = (run_time[i,j], RFC_train_accuracy[i,j], RFC_OOB_accuracy[i,j], RFC_test_accuracy[i,j], RFC_critical_accuracy[i,j])\n",
        "            print('{0:<15}{1:<15}{2:<15}{3:<15}{4:<15}'.format(\"time (s)\",\"train score\", \"OOB estimate\",\"test score\", \"critical score\"))\n",
        "            print('{0:<15.4f}{1:<15.4f}{2:<15.4f}{3:<15.4f}{4:<15.4f}'.format(*result))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Grafico delle prestazioni:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure()\n",
        "plt.plot(n_estimator_range,RFC_train_accuracy[1],'--b^',label='Train (bassa segmentazione)')\n",
        "plt.plot(n_estimator_range,RFC_test_accuracy[1],'--r^',label='Test (bassa segmentazione)')\n",
        "plt.plot(n_estimator_range,RFC_critical_accuracy[1],'--g^',label='Critical (bassa segmentazione)')\n",
        "\n",
        "plt.plot(n_estimator_range,RFC_train_accuracy[0],'o-b',label='Train (alta segmentazione)')\n",
        "plt.plot(n_estimator_range,RFC_test_accuracy[0],'o-r',label='Test (alta segmentazione)')\n",
        "plt.plot(n_estimator_range,RFC_critical_accuracy[0],'o-g',label='Critical (alta segmentazione)')\n",
        "\n",
        "plt.xlabel('$N_\\mathrm{estimators}$')\n",
        "plt.ylabel('Accuracy')\n",
        "lgd=plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.savefig(\"Ising_RF.pdf\",bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.plot(n_estimator_range, run_time[1], '--k^',label='Bassa segmentazione')\n",
        "plt.plot(n_estimator_range, run_time[0], 'o-k',label='Alta segmentazione')\n",
        "plt.xlabel('$N_\\mathrm{estimators}$')\n",
        "plt.ylabel('Run time (s)')\n",
        "\n",
        "\n",
        "plt.legend(loc=2)\n",
        "#plt.savefig(\"Ising_RF_Runtime.pdf\")\n",
        "\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Esercizi: ###  \n",
        "\n",
        "* provate a implementare invece che una validazione OOB (gratis con le foreste random in scikit-learn) una k-fold validation (con k=5 e 10) e verificate se vi sono differenze (OOB tende a dare delle stime molto pessimistiche).\n",
        "    \n",
        "NOTA: per imparare ad implementare una k-fold validation in scikit-learn guardate a questo [tutorial](https://scikit-learn.org/stable/modules/cross_validation.html)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
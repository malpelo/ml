{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBljQkfICznP"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/raeubaen/giagu/blob/master/NB_randomforest_ising2D_LC1_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83_hDEaJCznS"
   },
   "source": [
    "# Classificazione stato di un modello di Ising 2D con Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "94JHPP24CznV",
    "outputId": "852b6c12-826b-4563-ca4e-506e866f0534"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    drive_path = '/content/drive/My Drive'\n",
    "except (ModuleNotFoundError, KeyError): # Ho Google Drive montato localmente col file-system FUSE\n",
    "    drive_path = '/home/ruben/google-drive' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPPv2CeoCznl"
   },
   "source": [
    "### Informazioni ###\n",
    "\n",
    "* Scopo: imparare ad usare ensamble di modelli deboli tipo foreste random di alberi a decisione binaria \n",
    "* applicazione: classificazione dello fase in cui si trovano configurazioni di un modello di Ising 2D <br>\n",
    "* ML tool: scikit-learn\n",
    "\n",
    "\n",
    "### Modello di Ising 2D ###\n",
    "\n",
    "dettagli (definizione teorica e simulazione) nella [nota](https://vixra.org/pdf/1710.0021v2.pdf).\n",
    "\n",
    "È definito su un reticolo bidimensionale dall'Hamiltoniana \n",
    "\n",
    "$$ H = -J\\sum_{\\langle ij\\rangle}S_{i}S_j,\\qquad \\qquad S_j\\in\\{\\pm 1\\} $$\n",
    "\n",
    "in cui gli indici del reticolo $i,j$ sono associati ai primi vicini di un reticolo 2D quadrato di lato $L$, e $J$ è un parametro di scala arbitrario che definisce la scala dell'energia di interazione tra gli spin $S_i$.\n",
    "Si utilizzano condizioni periodiche al contorno sul reticolo.\n",
    "\n",
    "Si dimostra che questo sistema presenta una transizione di fase nel limite termodinamico da un sistea ordinato con tutti gli spin allineati (ferromagnete ordinato) a una fase disordinata con spin random, alla temperatura critica $T_c/J=1/\\log(1+\\sqrt{2})\\approx 2.26$. \n",
    "\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "100k configurazioni con $T/J$ uniforme in $[0,5]$ di un modello ising 2D su un reticolo $28\\times 28$ simulato tramite un semplice Monte Carlo tipo Metropolis. \n",
    "\n",
    "Il campione è disponibile qui:\n",
    "\n",
    "* [configurazioni](https://www.dropbox.com/s/ma1n1r2uejb9iei/ising_conf.dat?dl=0)\n",
    "* [label](https://www.dropbox.com/s/dj1urxh8tsadoh5/ising_label.dat?dl=0)\n",
    "\n",
    "NOTA: le configurazioni sono 28x28 valori dello spin, le label sono la temperatura associata ad ogni configurazione.\n",
    "\n",
    "Poiché è noto che vicino alla temepratura critica $T_c$, la lunghezza delle correlazioni ferromagnetiche diverge, rendendo difficile identificare la fase, dvideremo il campione in tre sotto-campioni:\n",
    "\n",
    "* ordinato: $T/J<2.0$\n",
    "* critico: $2.0\\leq T/J\\leq 2.5$\n",
    "* disordinato: $T/J>2.5$\n",
    "\n",
    "e addestreremo il modello usando solo le configurazioni ordinate e disordinate. Poi testeremo il tutto su tutte le configurazioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UiYnmdh4Cznn"
   },
   "source": [
    "### Parte 1: load e pre-processamento del dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FjkVGl7Cznp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed() # shuffle random seed generator\n",
    "\n",
    "# Ising model parameters\n",
    "L = 28 # size del reticolo\n",
    "J = 1.0 # Ising interaction (1 ferromagnetico, -1 anti-ferromagnetico)\n",
    "T_c = 2.26 # Temperatura critica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FTiJo_rTCzny",
    "outputId": "dbf9ba56-27c4-4865-dd4f-4aca4e35081b"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-23-c709e83fdd93>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-c709e83fdd93>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    file_name = f\"{drive_path}/Colab Notebooks/dataset/ising_conf.dat'\u001b[0m\n\u001b[0m                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#leggiamo le configurazioni ising dal file usando numpy \n",
    "# (100k esempi oguno da 28x28 spin)\n",
    "file_name = f\"{drive_path}/Colab Notebooks/dataset/ising_conf.dat'\n",
    "data = np.loadtxt(file_name)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgRsOy8TCzn7"
   },
   "source": [
    "NOTA: gli esempi sono scritti nel file come righe sequenziali da 28 valori l'una -> 100k x 28 = 2800000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fKZngT_1Czn9",
    "outputId": "72dabccc-a853-4e70-d461-ed69697d1118"
   },
   "outputs": [],
   "source": [
    "# al fine di visualizzare alcune delle configurazioni \n",
    "# convertiamo il vettore numpy in un tensore di 100K eventi ognuno \n",
    "# formato da una matrice 28x28 di spin\n",
    "data = data.reshape(100000,28,28)\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "conf_num = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "uyEoWWFkCzoF",
    "outputId": "7e14c304-b607-4a38-c46a-acc04c2524b8"
   },
   "outputs": [],
   "source": [
    "#esempio\n",
    "import pandas as pd\n",
    "rnd = np.random.randint(0, conf_num)\n",
    "#stampa un evento come una matrice 28x28 di valori dello spin (-1,1)\n",
    "print(pd.DataFrame(data[rnd]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "xzHRtDl2FfIQ",
    "outputId": "a6748d54-6269-4fd4-d2cb-26022cf29304"
   },
   "outputs": [],
   "source": [
    "# plotta come un immagine la matrice precedente e quella successiva nell'array\n",
    "%matplotlib inline \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_conf(axarr, data_list, titles_list):\n",
    "  cmap_args=dict(cmap='binary')\n",
    "  for i in range(len(data_list)):\n",
    "    axarr[i].imshow(data_list[i], **cmap_args)\n",
    "    axarr[i].set_title(titles_list[i], fontsize=16)\n",
    "    axarr[i].tick_params(labelsize=16)\n",
    "\n",
    "# plot states\n",
    "fig, axarr = plt.subplots(nrows=1, ncols=2)\n",
    "plot_conf(axarr, [data[rnd], data[rnd-1]], [\"\", \"\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "bw1HLTIXCzoO",
    "outputId": "e993157d-0fc5-4055-8f14-404e4be87faa"
   },
   "outputs": [],
   "source": [
    "#leggiamo da file le label associate:\n",
    "labels = np.loadtxt(f\"{drive_path}/Colab Notebooks/dataset/ising_label.dat\")\n",
    "print(labels.shape)\n",
    "print(f\"T/J: {labels[rnd]}\") #T/J della configurazione dell'evento mostrato prima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "HUQKDd_NbrJP",
    "outputId": "2fc154ce-430e-481e-bc35-9c87aa419f03"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4750aa7c0e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnd_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmagn_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagn_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "rnd_indexes = np.random.permutation(labels.shape[0])[:1000]\n",
    "data_subset = data[rnd_indexes, ...]\n",
    "labels_subset = labels[rnd_indexes, ...]\n",
    "magn_subset = np.array([np.abs(conf.mean()) for conf in data_subset])\n",
    "plt.scatter(labels_subset, magn_subset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "ji8RmAwhCzoU",
    "outputId": "127a620d-24d8-4b54-85dc-af57c5c7d663"
   },
   "outputs": [],
   "source": [
    "# dividiamo il campione in 3 campioni sulla base dello stato \n",
    "# (ordinato, critico, disordinato)\n",
    "# T/J < 2.0 ordinato\n",
    "# T/J > 2.5 disordinato\n",
    "# altrimenti critico\n",
    "\n",
    "ord_sele = (labels < 2.0)\n",
    "dis_sele = (labels > 2.5)\n",
    "cri_sele = ((labels >= 2.0) & (labels <= 2.5))\n",
    "    \n",
    "data_ord, n_ord = data[ord_sele], np.sum(ord_sele)\n",
    "data_dis, n_dis = data[dis_sele], np.sum(dis_sele)\n",
    "data_cri, n_cri = data[cri_sele], np.sum(cri_sele)\n",
    "\n",
    "print(f\"Number of ordered configurations:\\t{n_ord}\") \n",
    "print(f\"Number of disordered configurations:\\t{n_dis}\") \n",
    "print(f\"Number of critical configurations:\\t{n_cri}\") \n",
    "\n",
    "labels_ord = np.zeros(data_ord.shape[0])\n",
    "labels_dis = np.ones(data_dis.shape[0])\n",
    "labels_critic = labels[cri_sele]\n",
    "\n",
    "labels_cri = labels_critic.copy()\n",
    "labels_cri[labels_critic>T_c] = 1\n",
    "labels_cri[labels_critic<=T_c] = 0\n",
    "\n",
    "print(f\"Ordered Conf. labels:\\t\\t\\t{labels_ord}\")\n",
    "print(f\"Disordered Conf. labels:\\t\\t{labels_dis}\")\n",
    "print(f\"Critical Conf. labels:\\t\\t\\t{labels_cri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "iydS6dzgCzoc",
    "outputId": "d86b541c-3307-48aa-963a-e92339f4e26c"
   },
   "outputs": [],
   "source": [
    "#una rappresentazione grafica più bella\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# plot states\n",
    "fig, axarr = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "plot_conf(\n",
    "    axarr, \n",
    "    [data_ord[4], data_cri[4], data_dis[4]], \n",
    "    ['ordered phase', 'critical region', 'disordered phase'],\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(right=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "whVAuz5BCzoj",
    "outputId": "7c5e9ea1-eb10-494b-c002-00cce94a2eea"
   },
   "outputs": [],
   "source": [
    "##Dividiamo il campione per il training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_to_test_ratio = 0.8 # training samples\n",
    "\n",
    "# define training and test data sets\n",
    "X = np.concatenate((data_ord,data_dis))\n",
    "Y = np.concatenate((labels_ord,labels_dis))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, \n",
    "    train_size=train_to_test_ratio,\n",
    "    test_size=1.0 - train_to_test_ratio\n",
    ")\n",
    "\n",
    "X_critical = data_cri\n",
    "Y_critical = labels_cri\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(f'Y_train shape: {Y_train.shape}\\n')\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_critical.shape[0], 'critical samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# riformattiamo i tensori in modo che abbiano \n",
    "# l'input corretto atteso dagli alberi a decisione binaria \n",
    "# (vettori flat di features)   (N,28,28) -> (N, 28*28 = 784)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 28*28))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 28*28))\n",
    "X_critical = np.reshape(X_critical, (X_critical.shape[0], 28*28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSuezzIsCzoq"
   },
   "source": [
    "### Parte 2: addestramento della Random Forests\n",
    "\n",
    "**Iperparametri**\n",
    "\n",
    "Usiamo l'implementazione in [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) che ha due iperparamteri principali che possono modificare anche sensibimente le prestazioni del modello e il livelo di overfit/underfit: il numero di alberi nella foresta e la complessità di ciascun albero: il primo è controllato dal parametro `n_estimators`, mentre la complesiità è controllata da vari parametri `min_samples_split`, `min_samples_leaf`, `min_impurity_decrease`, etc, in parte correlati tra loro. Nell'esempio in esame per semplicità useremo solo `min_samples_split` (governa il numero di campioni necessari per procedere ad uno split di un nodo: più alto è il numero minore sarà la segmentazione e le diramazioni dell'albero.\n",
    "\n",
    "**NOTA: Stime OOB (Out of Bag)**\n",
    "\n",
    "È un metodo molto utile per ottimizzare gli iperparametri quando si usano metodi di bagging: consiste nel verificare quanto bene funziona il classificatore su quegli eventi del training set che non sono stati usati nel training (perchè non campionati nella technica di boostrap). Gioca un ruolo simile alla k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TUQj_nyRCzos",
    "outputId": "89cfa0ba-9d39-46db-8a56-b3cd27befb7e"
   },
   "outputs": [],
   "source": [
    "# Scikit-learn Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "import warnings\n",
    "#disabilitiamo messaggi di warning \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Valore del numero di alberi \n",
    "min_estimators = 10\n",
    "max_estimators = 101\n",
    "classifer = RandomForestClassifier\n",
    "\n",
    "#testiamo 10 valori per il primo iperparametro\n",
    "n_estimator_range = np.arange(min_estimators, max_estimators, 10) \n",
    "\n",
    "#testiamo due valori per il seocondo iperparametro \n",
    "# (alta segmentazione e bassa segmentazione)\n",
    "leaf_size_list = [2, 10000] \n",
    "\n",
    "m = len(n_estimator_range)\n",
    "n = len(leaf_size_list)\n",
    "\n",
    "#Allocate Arrays for various quantities\n",
    "RFC_OOB_accuracy = np.zeros((n, m))\n",
    "RFC_train_accuracy = np.zeros((n, m))\n",
    "RFC_test_accuracy = np.zeros((n, m))\n",
    "RFC_critical_accuracy = np.zeros((n, m))\n",
    "run_time = np.zeros((n, m))\n",
    "\n",
    "print_flag = True\n",
    "\n",
    "for i, leaf_size in enumerate(leaf_size_list):\n",
    "    # Define Random Forest Classifier\n",
    "    myRF_clf = classifer(\n",
    "        n_estimators=min_estimators,\n",
    "        max_depth=None, \n",
    "        min_samples_split=leaf_size, # minimum number of sample per leaf\n",
    "        oob_score=True,\n",
    "        random_state=0,\n",
    "        warm_start=True \n",
    "        # When set to True, reuses the solution of the previous call to fit and \n",
    "        # adds more estimators to the ensemble, otherwise fits a new forest.\n",
    "    )\n",
    "\n",
    "    for j, n_estimator in enumerate(n_estimator_range):\n",
    "        \n",
    "        print('n_estimators: %i, leaf_size: %i'%(n_estimator, leaf_size))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        myRF_clf.set_params(n_estimators=n_estimator)\n",
    "        myRF_clf.fit(X_train, Y_train)\n",
    "        run_time[i,j] = time.time() - start_time\n",
    "\n",
    "    # check accuracy\n",
    "        RFC_train_accuracy[i,j]=myRF_clf.score(X_train, Y_train)\n",
    "        RFC_OOB_accuracy[i,j]=myRF_clf.oob_score_\n",
    "        RFC_test_accuracy[i,j]=myRF_clf.score(X_test, Y_test)\n",
    "        RFC_critical_accuracy[i,j]=myRF_clf.score(X_critical, Y_critical)\n",
    "        if print_flag:\n",
    "            result = (\n",
    "                run_time[i,j], \n",
    "                RFC_train_accuracy[i,j], \n",
    "                RFC_OOB_accuracy[i,j], \n",
    "                RFC_test_accuracy[i,j], \n",
    "                RFC_critical_accuracy[i,j]\n",
    "            )\n",
    "            print(\n",
    "                '{0:<15}{1:<15}{2:<15}{3:<15}{4:<15}'.format(\n",
    "                    \"time (s)\",\n",
    "                    \"train score\", \n",
    "                    \"OOB estimate\",\n",
    "                    \"test score\", \n",
    "                    \"critical score\"\n",
    "                )\n",
    "            )\n",
    "            print(\n",
    "                '{0:<15.4f}{1:<15.4f}{2:<15.4f}{3:<15.4f}{4:<15.4f}'.format(\n",
    "                    *result\n",
    "                )\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jd5mr4DVCzoz"
   },
   "source": [
    "**Grafico delle prestazioni:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "id": "yoBRSrhJCzo0",
    "outputId": "045c757f-e5c0-4a87-d151-654142002200"
   },
   "outputs": [],
   "source": [
    "def plot_performance(RFC_train_acc, RFC_test_acc, RFC_critic_acc):\n",
    "    fig, axs = plt.subplots(2, figsize=(10, 10))\n",
    "    ner = n_estimator_range\n",
    "    ax0 = axs[0]\n",
    "    ax0.plot(ner, RFC_train_acc[1],'--b^',label='Train (bassa segmentazione)')\n",
    "    ax0.plot(ner, RFC_test_acc[1],'--r^',label='Test (bassa segmentazione)')\n",
    "    ax0.plot(ner, RFC_critic_acc[1],'--g^',label='Critical (bassa segmentazione)')\n",
    "\n",
    "    ax0.plot(ner, RFC_train_acc[0],'o-b',label='Train (alta segmentazione)')\n",
    "    ax0.plot(ner, RFC_test_acc[0],'o-r',label='Test (alta segmentazione)')\n",
    "    ax0.plot(ner, RFC_critic_acc[0],'o-g',label='Critical (alta segmentazione)')\n",
    "\n",
    "    ax0.set(xlabel='$N_\\mathrm{estimators}$', ylabel='Accuracy')\n",
    "    lgd = ax0.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    ax1 = axs[1]\n",
    "    ax1.plot(ner, run_time[1], '--k^',label='Bassa segmentazione')\n",
    "    ax1.plot(ner, run_time[0], 'o-k',label='Alta segmentazione')\n",
    "    ax1.set(xlabel='$N_\\mathrm{estimators}$', ylabel='Run time (s)')\n",
    "\n",
    "    ax1.legend(loc=2)\n",
    "    #plt.savefig(\"Ising_RF_Runtime.pdf\")\n",
    "    return (fig, axs)\n",
    "\n",
    "fig, axs = plot_performance(\n",
    "    RFC_train_accuracy, RFC_test_accuracy, RFC_critical_accuracy\n",
    ")\n",
    "axs[0].set(title=\"Accuracy vs Estimators Number - OOP\")\n",
    "axs[1].set(title=\"Runtime vs Estimators Number - OOP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yxdXxUa6Czo-"
   },
   "source": [
    "### Esercizi: ###  \n",
    "\n",
    "* provate a implementare invece che una validazione OOB (gratis con le foreste random in scikit-learn) una k-fold validation (con k=5 e 10) e verificate se vi sono differenze (OOB tende a dare delle stime molto pessimistiche).\n",
    "    \n",
    "NOTA: per imparare ad implementare una k-fold validation in scikit-learn guardate a questo [tutorial](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Nu8lQOmZiddd",
    "outputId": "3fd5c36d-4a85-4ec3-b18c-c165d525cd33"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "RFC_cv_accuracy = np.zeros((n, m))\n",
    "n_folds = 5\n",
    "\n",
    "def train_k_folds(n_folds):\n",
    "    for i, leaf_size in enumerate(leaf_size_list):\n",
    "        myRF_clf = classifer(\n",
    "                n_estimators=min_estimators,\n",
    "                max_depth=None, \n",
    "                min_samples_split=leaf_size, # minimum number of sample per leaf\n",
    "                oob_score=False, #now we use k-fold CV\n",
    "                random_state=0,\n",
    "                warm_start=True \n",
    "            )\n",
    "        for j, n_estimator in enumerate(n_estimator_range):\n",
    "            \n",
    "            print('n_estimators: %i, leaf_size: %i'%(n_estimator, leaf_size))\n",
    "                # Define Random Forest Classifier\n",
    "            myRF_clf.set_params(n_estimators=n_estimator)\n",
    "            # StratifiedKFold preserves proportion between labels in  k-folds\n",
    "            skf = StratifiedKFold(n_splits=n_folds) \n",
    "            scores = []\n",
    "\n",
    "            start_time = time.time()\n",
    "            for train_index, test_index in skf.split(X_train, Y_train):\n",
    "              X_cv_train, X_cv_test = X_train[train_index], X_train[test_index]\n",
    "              Y_cv_train, Y_cv_test = Y_train[train_index], Y_train[test_index]\n",
    "              myRF_clf.fit(X_cv_train, Y_cv_train)\n",
    "              scores.append(myRF_clf.score(X_cv_test, Y_cv_test))\n",
    "            run_time[i,j] = time.time() - start_time\n",
    "\n",
    "        # check accuracy\n",
    "            RFC_train_accuracy[i,j] = myRF_clf.score(X_train, Y_train)\n",
    "            RFC_cv_accuracy[i,j] = np.array(scores).mean()\n",
    "            RFC_test_accuracy[i,j] = myRF_clf.score(X_test, Y_test)\n",
    "            RFC_critical_accuracy[i,j] = myRF_clf.score(X_critical, Y_critical)\n",
    "            if print_flag:\n",
    "                result = (\n",
    "                    run_time[i,j], \n",
    "                    RFC_train_accuracy[i,j], \n",
    "                    RFC_cv_accuracy[i,j], \n",
    "                    RFC_test_accuracy[i,j], \n",
    "                    RFC_critical_accuracy[i,j]\n",
    "                )\n",
    "                print(\n",
    "                    '{0:<15}{1:<15}{2:<15}{3:<15}{4:<15}'.format(\n",
    "                        \"time (s)\",\n",
    "                        \"train score\", \n",
    "                        \"CV score\",\n",
    "                        \"test score\", \n",
    "                        \"critical score\"\n",
    "                    )\n",
    "                )\n",
    "                print(\n",
    "                    '{0:<15.4f}{1:<15.4f}{2:<15.4f}{3:<15.4f}{4:<15.4f}'.format(\n",
    "                        *result\n",
    "                    )\n",
    "                )\n",
    "    out = (\n",
    "        RFC_train_accuracy, RFC_cv_accuracy, \n",
    "        RFC_test_accuracy, RFC_critical_accuracy\n",
    "    )\n",
    "    return out\n",
    "\n",
    "RFC_train_acc, RFC_cv_acc, RFC_test_acc, RFC_critical_acc = train_k_folds(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "id": "NpE4BPVzqjOF",
    "outputId": "8d427b8f-26f9-41c2-c5e1-a81ed7985616"
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_performance(\n",
    "    RFC_train_accuracy, RFC_test_accuracy, RFC_critical_accuracy\n",
    ")\n",
    "axs[0].set(title=\"Accuracy vs $N_{estimators}$ - Stratified 5-fold CV\")\n",
    "axs[1].set(title=\"Runtime vs $N_{estimators}$ - Stratified 5-fold CV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLOTr4QatPYV"
   },
   "source": [
    "Grazie al processo di media tra gli scores delle singole validazioni e grazie al fatto che, essendo il dataset in questione essenzialmente stocastico, i sottogruppi estratti con la stratified k-fold cross validation sono abbastanza indipendenti ed identicamente distribuiti, il cross-validation score in questo caso dà risutati identici allo score su tutto il training set, a differenza dell'OOP usato in precedenza.\n",
    "Rieseguiamo lo stesso processo con `n_folds = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sBe4oQhtuexh",
    "outputId": "2b707692-8cad-4c70-a9ec-c3ce4c305db1"
   },
   "outputs": [],
   "source": [
    "RFC_train_acc, RFC_cv_acc, RFC_test_acc, RFC_critical_acc = train_k_folds(10)\n",
    "fig, axs = plot_performance(\n",
    "    RFC_train_accuracy, RFC_test_accuracy, RFC_critical_accuracy\n",
    ")\n",
    "axs[0].set(title=\"Accuracy vs $N_{estimators}$ - Stratified 10-fold CV\")\n",
    "axs[1].set(title=\"Runtime vs $N_{estimators}$ - Stratified 10-fold CV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCYknZWkyf2C"
   },
   "source": [
    "Com'era prevedibile, dato che già con 5 folds si aveva `train_accuracy = cv_accuracy`, tale comportamento permane anche con 10 folds. <br>\n",
    "Di contro, si ha un aumento di circa 1 secondo sul runtime per ogni istanza di fit."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "NB_randomforest_ising2D_LC1_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit3d274c29e8a44b108e00b218e49e15f7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

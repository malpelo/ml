{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/raeubaen/giagu/blob/master/NB_PCA_tSNE_LC1_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualizzazione di dataset con PCA e tSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Informazioni ###\n",
        "\n",
        "scopo: impratichirsi con le operazioni di data-esploration utilizzando le tecniche di riduzione dimensionale PCA e tSNE.\n",
        "\n",
        "**Il dataset MNIST**\n",
        "\n",
        "Il dataset [MNIST](http://yann.lecun.com/exdb/mnist/) \u00e8 uno dei dataset di bechmark pi\u00f9 utlizzati nel ML. Prodotto da Yann LeCun che ha collezionato 70000 immagini di numeri scritti a mano (60000 per il training e 10000 per test). Ogni immagine \u00e8 rappresentata da una matrice di 28x28 pixel oguno con una intensit\u00e0 nel range $[0,255]$ che rappresenta 256 variazioni del livello di grigio di quel pixel. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#import delle librerie necessarie\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "#import seaborn as sns"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 1: load del dataset MNIST e data preprocessing\n",
        "\n",
        "questo \u00e8 disponibile vari frameowrk per ML noi utilizzeremo Tensorflow ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "#convertiamo i dati in f32 e normalizziamo in [0,1] --> usiamo solo il campione di training in questo esempio\n",
        "X = x_train.astype('float32')\n",
        "X /= 255\n",
        "y = y_train\n",
        "print(X.shape, y.shape) #output "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# per comodit\u00e0 convertiamo le matrici che rappresentano i dati in undataframe di pandas\n",
        "import pandas as pd\n",
        "\n",
        "# rendiamo flat le matrici\n",
        "X = np.reshape(X,(60000,28*28))\n",
        "\n",
        "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
        "df = pd.DataFrame(X,columns=feat_cols)\n",
        "df['y'] = y\n",
        "df['label'] = df['y'].apply(lambda i: str(i))\n",
        "X, y = None, None\n",
        "print('Size of the dataframe: {}'.format(df.shape))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# randomizziamo i dati (sempre buona cosa)\n",
        "\n",
        "# For reproducability of the results\n",
        "np.random.seed(1234)\n",
        "\n",
        "rndperm = np.random.permutation(df.shape[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Esempio di come con Pandas \u00e8 semplice graficare un dataset ...\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "plt.gray()\n",
        "fig = plt.figure( figsize=(16,7) )\n",
        "for i in range(0,15):\n",
        "    ax = fig.add_subplot(3,5,i+1, title=\"Digit: {}\".format(str(df.loc[rndperm[i],'label'])) )\n",
        "    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((28,28)).astype(float))\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 2: PCA \n",
        "\n",
        "utilizzeremo l'implementazione PCA disponibile dentro scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#consideriamo solo le prime tre componenti\n",
        "pca = PCA(n_components=3)\n",
        "pca_result = pca.fit_transform(df[feat_cols].values)\n",
        "\n",
        "df['pca-one'] = pca_result[:,0]\n",
        "df['pca-two'] = pca_result[:,1] \n",
        "df['pca-three'] = pca_result[:,2]\n",
        "\n",
        "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "\n",
        "#NOTA: l'explained variation indica quanto ciascuna componente contribusice alla varianza totale del campione"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#grafichiamo le prime due componenti\n",
        "# per fare questo facciamo uno scatter plot delle due componenti e coloriamo ciaascun tipo di carattere con un \n",
        "# colore diverso ... questo pu\u00f2 essere fatto direttamente usando Pandas!\n",
        "\n",
        "ax = df.loc[rndperm,:].plot.scatter(x=\"pca-one\", y=\"pca-two\", c=\"y\", colormap='tab10')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#3d usando matplotlib ...\n",
        "\n",
        "ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
        "ax.scatter(\n",
        "    xs=df.loc[rndperm,:][\"pca-one\"], \n",
        "    ys=df.loc[rndperm,:][\"pca-two\"], \n",
        "    zs=df.loc[rndperm,:][\"pca-three\"], \n",
        "    c=df.loc[rndperm,:][\"y\"], \n",
        "    cmap='tab10'\n",
        ")\n",
        "ax.set_xlabel('pca-one')\n",
        "ax.set_ylabel('pca-two')\n",
        "ax.set_zlabel('pca-three')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 3: tSNE\n",
        "\n",
        "utilizzeremo l'implementazione tSNE disponibile dentro scikit-learn\n",
        "\n",
        "NOTA: tSNE \u00e8 molto pesante dal punto di vista computazionale (CPU e RAM) con complessit\u00e0 che scala quadraticamente con il numero di eventi nel campione. L'applicabilit\u00e0 \u00e8 limitata quindi a dataset di qualche migliaio di eventi, oppure bisogna prima di usarlo ridurre la dimensionalit\u00e0 con PCA (esempio $28\\times 28 \\to $ PCA $\\to 25 \\to$ tSNE, oppure usare meno campioni.\n",
        "\n",
        "In questo caso usiamo tutte le 28x28 \"features\" ma usiamo solo 10k eventi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# selezioniamo i primi 10k eventi dal dataframe \n",
        "N = 10000\n",
        "df_subset = df.loc[rndperm[:N],:].copy()\n",
        "data_subset = df_subset[feat_cols].values\n",
        "\n",
        "# calcoliamo di nuovo la PCA per confrontarci con tSNE\n",
        "pca = PCA(n_components=3)\n",
        "pca_result = pca.fit_transform(data_subset)\n",
        "df_subset['pca-one'] = pca_result[:,0]\n",
        "df_subset['pca-two'] = pca_result[:,1] \n",
        "df_subset['pca-three'] = pca_result[:,2]\n",
        "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# tSNE\n",
        "\n",
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(data_subset)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
        "df_subset['tsne-2d-two'] = tsne_results[:,1]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#confrontiamo i risultati PCA vs tSNE\n",
        "plt.figure(figsize=(16,7))\n",
        "\n",
        "ax1 = plt.subplot(1, 2, 1)\n",
        "df_subset.plot.scatter(x=\"pca-one\", y=\"pca-two\", c=\"y\", colormap='tab10', ax=ax1)\n",
        "\n",
        "ax2 = plt.subplot(1, 2, 2)\n",
        "df_subset.plot.scatter(x=\"tsne-2d-one\", y=\"tsne-2d-two\", c=\"y\", colormap='tab10', ax=ax2)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#proviamo PCA + tSNE:\n",
        "\n",
        "pca_50 = PCA(n_components=50)\n",
        "pca_result_50 = pca_50.fit_transform(data_subset)\n",
        "print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))\n",
        "\n",
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)\n",
        "tsne_pca_results = tsne.fit_transform(pca_result_50)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_subset['tsne-pca50-one'] = tsne_pca_results[:,0]\n",
        "df_subset['tsne-pca50-two'] = tsne_pca_results[:,1]\n",
        "\n",
        "ax4=df_subset.plot.scatter(x=\"tsne-pca50-one\", y=\"tsne-pca50-two\", c=\"y\", colormap='tab10')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}